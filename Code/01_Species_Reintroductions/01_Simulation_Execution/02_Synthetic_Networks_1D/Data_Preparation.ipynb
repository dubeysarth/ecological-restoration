{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "while os.getcwd().split('\\\\')[-1] != 'ecological-networks':\r\n",
    "    %cd ..\r\n",
    "import setup_paths \r\n",
    "setup_paths.add_path()\r\n",
    "from Species_Reintroductions import *\r\n",
    "DATA_TYPE = 'Syn_1D'\r\n",
    "CASE_TO_SOLVE_init(DATA_TYPE)\r\n",
    "get_CASE()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Log_History = Write_Log(os.path.join(os.getcwd(), 'Code', '01_Species_Reintroductions', '01_Simulation_Execution', '02_Synthetic_Networks_1D', 'Log_Execution.txt'), True)\r\n",
    "#Log_Record = Write_Log(os.path.join(os.getcwd(), 'Code', '01_Species_Reintroductions', '01_Simulation_Execution', '02_Synthetic_Networks_1D', 'Log_Record.txt'), True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_SyntheticData_type01(A = 0.5, C = 0.2, S = 50, seed = 0):\r\n",
    "    N = round(S / (1+A))\r\n",
    "    M = round((S*A) / (1+A))\r\n",
    "    L = round(C*N*M)\r\n",
    "\r\n",
    "    X = np.zeros((N,M),int)\r\n",
    "    np.fill_diagonal(X,1)\r\n",
    "    \r\n",
    "    np.random.seed(seed)\r\n",
    "    \r\n",
    "    non_filled_rows = np.array(list(itertools.product(np.arange(M,N),np.arange(M))))\r\n",
    "    idx = np.array(np.random.choice(len(non_filled_rows),N-M))\r\n",
    "    \r\n",
    "    for i in range(N-M):\r\n",
    "        X[non_filled_rows[idx[i]][0],non_filled_rows[idx[i]][1]] = 1\r\n",
    "    \r\n",
    "    non_filled_cells = np.argwhere(X==0)\r\n",
    "    idx = np.array(np.random.choice(len(non_filled_cells),L - N))\r\n",
    "    \r\n",
    "    for i in range(L - N):\r\n",
    "        X[non_filled_cells[idx[i]][0],non_filled_cells[idx[i]][1]] = 1\r\n",
    "    \r\n",
    "    if np.all(np.sum(X,axis = 1) > 0) and np.all(np.sum(X,axis = 0) > 0):\r\n",
    "        nodf_score = NestednessCalculator(X).nodf(X)\r\n",
    "        #print(nodf_score)\r\n",
    "        \r\n",
    "        M_df = pd.DataFrame(X)\r\n",
    "        M_df.columns = np.char.add('B',np.array(range(len(M_df.columns)), dtype = 'str'))\r\n",
    "        M_df.index = np.char.add('A',np.array(range(len(M_df.index)), dtype = 'str'))\r\n",
    "        \r\n",
    "        return M_df, nodf_score\r\n",
    "    else:\r\n",
    "        return pd.DataFrame(np.zeros((N,M),int)),0.0\r\n",
    "\r\n",
    "def get_SyntheticData_type02(N = 33, M = 17, L = 112, seed = 0):\r\n",
    "    X = np.zeros((N,M),int)\r\n",
    "    np.fill_diagonal(X,1)\r\n",
    "    \r\n",
    "    np.random.seed(seed)\r\n",
    "    \r\n",
    "    non_filled_rows = np.array(list(itertools.product(np.arange(M,N),np.arange(M))))\r\n",
    "    idx = np.array(np.random.choice(len(non_filled_rows),N-M))\r\n",
    "    \r\n",
    "    for i in range(N-M):\r\n",
    "        X[non_filled_rows[idx[i]][0],non_filled_rows[idx[i]][1]] = 1\r\n",
    "    \r\n",
    "    non_filled_cells = np.argwhere(X==0)\r\n",
    "    idx = np.array(np.random.choice(len(non_filled_cells),L - N))\r\n",
    "    \r\n",
    "    for i in range(L - N):\r\n",
    "        X[non_filled_cells[idx[i]][0],non_filled_cells[idx[i]][1]] = 1\r\n",
    "    \r\n",
    "    if np.all(np.sum(X,axis = 1) > 0) and np.all(np.sum(X,axis = 0) > 0):    \r\n",
    "        nodf_score = NestednessCalculator(X).nodf(X)\r\n",
    "        #print(nodf_score)\r\n",
    "        \r\n",
    "        M_df = pd.DataFrame(X)\r\n",
    "        M_df.columns = np.char.add('B',np.array(range(len(M_df.columns)), dtype = 'str'))\r\n",
    "        M_df.index = np.char.add('A',np.array(range(len(M_df.index)), dtype = 'str'))\r\n",
    "        \r\n",
    "        return M_df,nodf_score\r\n",
    "    else:\r\n",
    "        return pd.DataFrame(np.zeros((N,M),int)),0.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def init_SyntheticData(A = 0.5, C = 0.2, S = 50, ind = 0, FileObj = None):\r\n",
    "    M_df_collec = []\r\n",
    "    nodf_collec = []\r\n",
    "    for seed in range(1000):\r\n",
    "        M_df, nodf = get_SyntheticData_type01(A = A, C = C, S = S, seed = seed)\r\n",
    "        if nodf != 0:\r\n",
    "            M_df_collec.append(M_df)\r\n",
    "            nodf_collec.append(nodf)\r\n",
    "    del seed,M_df,nodf\r\n",
    "    X = pd.DataFrame()\r\n",
    "    X['idx'] = np.arange(len(nodf_collec))\r\n",
    "    X['nodf'] = nodf_collec\r\n",
    "    X = X.sort_values(by = 'nodf')\r\n",
    "    \r\n",
    "    M_df_selected  = [\r\n",
    "        M_df_collec[int(X.iloc[0]['idx'])],\r\n",
    "        M_df_collec[int(X.iloc[int(len(M_df_collec)/2)]['idx'])],\r\n",
    "        M_df_collec[int(X.iloc[-1]['idx'])]\r\n",
    "        ]\r\n",
    "    nodf_selected  = [\r\n",
    "        nodf_collec[int(X.iloc[0]['idx'])],\r\n",
    "        nodf_collec[int(X.iloc[int(len(M_df_collec)/2)]['idx'])],\r\n",
    "        nodf_collec[int(X.iloc[-1]['idx'])]\r\n",
    "        ]\r\n",
    "    if FileObj != None:FileObj.Log_Entry(\"S = {}, A = {}, C = {}\".format(S, A, C))\r\n",
    "    for ind_2 in range(3):\r\n",
    "        FileName = os.path.join(os.getcwd(), 'Code', '01_Species_Reintroductions', '02_Generate_Database', f\"{DATA_TYPE}_Data\", f\"M_PL_{S}_{ind}_{ind_2}\", f\"M_PL_{S}_{ind}_{ind_2}-Data_one.pkl\")\r\n",
    "        os.makedirs(os.path.dirname(FileName), exist_ok=True)\r\n",
    "        PickleObj(M_df_selected[ind_2], FileName)\r\n",
    "        if FileObj != None:FileObj.Log_Entry(str(nodf_selected[ind_2]) + ' : ' + f\"M_PL_{S}_{ind}_{ind_2}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "S = [100]\r\n",
    "A = [0.25, 0.50, 0.75]\r\n",
    "C = [0.05, 0.10, 0.15, 0.20]\r\n",
    "param_AC = list(itertools.product(S,A,C))\r\n",
    "for ind in range(len(param_AC)):\r\n",
    "    s,a,c = param_AC[ind]\r\n",
    "    #print(a,c)\r\n",
    "    #Log_Record.Log_Entry(\"{} : (S,A,C) = ({},{},{})\".format(ind,s,a,c))\r\n",
    "    try:\r\n",
    "        init_SyntheticData(A = a, C = c, S = s, ind = ind, FileObj = Log_History)\r\n",
    "    except:\r\n",
    "        pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Data_Preparation(\r\n",
    "    param_Segment01 = None,\r\n",
    "    param_Segment02 = [\r\n",
    "        10,                    ## param_Ensembles\r\n",
    "        np.arange(9),           ## param_Fraction\r\n",
    "        0,                      ## Start\r\n",
    "        None,                   ## End\r\n",
    "        1,                      ## Step\r\n",
    "        True,                   ## Overwrite \r\n",
    "        False,                  ## Display_Output\r\n",
    "        False                   ## Display_Count\r\n",
    "        ], \r\n",
    "    File_Obj = Log_History, \r\n",
    "    Record_Obj = None,\r\n",
    "    Record_Reset = False\r\n",
    "    );"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "M = UnpickleObj(os.path.join(os.getcwd(), 'Code', '01_Species_Reintroductions', '01_Simulation_Execution', f\"M_{DATA_TYPE.split('_')[0]}.pkl\"))\r\n",
    "WebOfLife_ID = list(UnpickleObj(os.path.join(os.getcwd(), 'Code', '01_Species_Reintroductions', '01_Simulation_Execution', f\"Network_Solved_{DATA_TYPE.split('_')[0]}.pkl\")).NetworkName)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for NetworkName in itertools.islice(WebOfLife_ID,31,32,1):\r\n",
    "    Solve_For_Network(\r\n",
    "        NetworkName = NetworkName,                  ## Network Name\r\n",
    "        Ensembles_batch = [0,10],                   ## Mini-Batch of Ensembles\r\n",
    "        Keys_Filter = [[0,1,2], [2,5,8], [0,2]],  ## Filter: Strategy, Fraction, Target\r\n",
    "        Flag = [True, True, True, True, True],      ## System, Degree, Closeness, Betweenness\r\n",
    "        Overwrite = True,                           ## Overwrite existing results\r\n",
    "        File_Obj = Log_History                      ## History of Operations\r\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "M = UnpickleObj(os.path.join(os.getcwd(), 'Code', '01_Species_Reintroductions', '01_Simulation_Execution', f\"M_{DATA_TYPE.split('_')[0]}.pkl\"))\r\n",
    "WebOfLife_ID = list(UnpickleObj(os.path.join(os.getcwd(), 'Code', '01_Species_Reintroductions', '01_Simulation_Execution', f\"Network_Solved_{DATA_TYPE.split('_')[0]}.pkl\")).NetworkName)\r\n",
    "\r\n",
    "Keys_Filter = [[0,1,2], [2,5,8], [0,2]]\r\n",
    "Ensembles_batch = [0,10]\r\n",
    "\r\n",
    "Flag = [True, True, True, True, True]\r\n",
    "\r\n",
    "## Done :- ind 0,29 (Left: 30,31)\r\n",
    "# 0:15\r\n",
    "# 0:20\r\n",
    "# 20:30\r\n",
    "if Log_History != None:\r\n",
    "    Log_History.Log_Entry('.......Solution Averaging.........')\r\n",
    "    Log_History.Log_Entry(\"Key Filter: {}\".format(Keys_Filter))\r\n",
    "    Log_History.Log_Entry(\"Ensembles Run: {}\".format(Ensembles_batch))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for NetworkName in itertools.islice(WebOfLife_ID,0,None,1):\r\n",
    "    M_df = M[NetworkName]\r\n",
    "    data_two = UnpickleObj(os.path.join(os.getcwd(), 'Code', '01_Species_Reintroductions', '02_Generate_Database', f\"{DATA_TYPE}_Data\", f\"{NetworkName}\", f\"{NetworkName}-Data_two.pkl\"))\r\n",
    "    data_two = {k: v[Ensembles_batch[0]:min(Ensembles_batch[1],len(v))] for k,v in data_two.items() if k in set(list(itertools.product(*Keys_Filter)))}\r\n",
    "    \r\n",
    "    if Log_History != None:\r\n",
    "        Log_History.Log_Entry('Network ID: ' + NetworkName)\r\n",
    "        Log_History.Log_Entry(\"Shape: {} ({})\".format(M_df.shape, sum(M_df.shape)))\r\n",
    "        \r\n",
    "    if Flag[0]:\r\n",
    "        try:\r\n",
    "            data_three = getDict_x(\r\n",
    "                ID = 'Data_three', \r\n",
    "                data_two = data_two, \r\n",
    "                NetworkName = NetworkName, \r\n",
    "                Shape = M_df.shape, \r\n",
    "                Steady_State_Correction = True\r\n",
    "                );\r\n",
    "            if Log_History != None:\r\n",
    "                Log_History.Log_Entry(\"{} ; {}\".format(NetworkName, 'System_Driven'))\r\n",
    "        except:\r\n",
    "            if Log_History != None:\r\n",
    "                Log_History.Log_Entry(\"FAILED!: {} ; {}\".format(NetworkName, 'System_Driven'))\r\n",
    "\r\n",
    "    if Flag[1]:\r\n",
    "        try:\r\n",
    "            data_four = getDict_x(\r\n",
    "                ID = 'Data_four', \r\n",
    "                data_two = data_two, \r\n",
    "                NetworkName = NetworkName, \r\n",
    "                Shape = M_df.shape, \r\n",
    "                Steady_State_Correction = True\r\n",
    "                );\r\n",
    "            if Log_History != None:\r\n",
    "                Log_History.Log_Entry(\"{} ; {}\".format(NetworkName, 'Degree_Driven'))\r\n",
    "        except:\r\n",
    "            if Log_History != None:\r\n",
    "                Log_History.Log_Entry(\"FAILED!: {} ; {}\".format(NetworkName, 'Degree_Driven'))\r\n",
    "\r\n",
    "    if Flag[2]:\r\n",
    "        try:\r\n",
    "            data_five = getDict_x(\r\n",
    "                ID = 'Data_five', \r\n",
    "                data_two = data_two, \r\n",
    "                NetworkName = NetworkName, \r\n",
    "                Shape = M_df.shape,\r\n",
    "                Steady_State_Correction = True\r\n",
    "                );\r\n",
    "            if Log_History != None:\r\n",
    "                Log_History.Log_Entry(\"{} ; {}\".format(NetworkName, 'Closeness_Driven'))\r\n",
    "        except:\r\n",
    "            if Log_History != None:\r\n",
    "                Log_History.Log_Entry(\"FAILED!: {} ; {}\".format(NetworkName, 'Closeness_Driven'))\r\n",
    "\r\n",
    "    if Flag[3]:\r\n",
    "        try:\r\n",
    "            data_six = getDict_x(\r\n",
    "                ID = 'Data_six', \r\n",
    "                data_two = data_two, \r\n",
    "                NetworkName = NetworkName, \r\n",
    "                Shape = M_df.shape, \r\n",
    "                Steady_State_Correction = True\r\n",
    "                );\r\n",
    "            if Log_History != None:\r\n",
    "                Log_History.Log_Entry(\"{} ; {}\".format(NetworkName, 'Betweenness_Driven'))\r\n",
    "        except:\r\n",
    "            if Log_History != None:\r\n",
    "                Log_History.Log_Entry(\"FAILED!: {} ; {}\".format(NetworkName, 'Betweenness_Driven'))\r\n",
    "            \r\n",
    "    if Flag[4]:\r\n",
    "        try:\r\n",
    "            data_rand = getDict_x(\r\n",
    "                ID = 'Data_rand', \r\n",
    "                data_two = data_two, \r\n",
    "                NetworkName = NetworkName, \r\n",
    "                Shape = M_df.shape, \r\n",
    "                Steady_State_Correction = True\r\n",
    "                );\r\n",
    "            if Log_History != None:\r\n",
    "                Log_History.Log_Entry(\"{} ; {}\".format(NetworkName, 'Random'))\r\n",
    "        except:\r\n",
    "            if Log_History != None:\r\n",
    "                Log_History.Log_Entry(\"FAILED!: {} ; {}\".format(NetworkName, 'Random'))\r\n",
    "    print(NetworkName)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\r\n",
    "    Log_History.close_Log()\r\n",
    "except:\r\n",
    "    pass\r\n",
    "try:\r\n",
    "    Log_Record.close_Log()\r\n",
    "except:\r\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('master': conda)"
  },
  "interpreter": {
   "hash": "0c640dc386691b1b42b3424c708d4d1eda291d0197a35eddf54ba99eb6d636bd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}